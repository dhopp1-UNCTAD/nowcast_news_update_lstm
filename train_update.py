import datetimefrom dateutil.relativedelta import relativedeltaimport pandas as pdimport numpy as npimport torchimport dillimport osfrom nowcast_lstm.LSTM import LSTM### function to add last dates neededdef add_last_dates(data, target_period):    dataset = data.copy()    last_date = datetime.datetime.strptime(        datetime.datetime.strftime(np.max(dataset.date), "%Y-%m-%d"), "%Y-%m-%d"    )    period_date = datetime.datetime.strptime(target_period, "%Y-%m-%d")    months_add = (period_date.year - last_date.year) * 12 + (        period_date.month - last_date.month    )    if months_add > 0:        for i in range(months_add):            dataset.loc[len(dataset), "date"] = dataset.loc[                len(dataset) - 1, "date"            ] + relativedelta(months=1)    return dataset### data informationdata_directory = "/Users/danhopp/dhopp1/UNCTAD/nowcast_data_update/"unctad_web_directory = "/Users/danhopp/dhopp1/UNCTAD/unctad-nowcast-web/"news_history = pd.read_csv(unctad_web_directory + "nowcasts/data/lstm.csv")retrain = Falsetargets = ["x_world", "x_vol_world2", "x_servs_world"]target_periods = ["2020-06-01"]next_period = datetime.datetime.strptime(max(target_periods), "%Y-%m-%d") + relativedelta(months = 3)while (next_period - datetime.datetime.today()).days <= 93: # only do if next period is less than 93 days    target_periods.append(datetime.datetime.strftime(next_period, "%Y-%m-%d"))    next_period = datetime.datetime.strptime(max(target_periods), "%Y-%m-%d") + relativedelta(months = 3)# final model parameters and variables from selectionvariables_dict = {}variables_dict["x_world"] = ['x_world', 'bci_nl', 'constr_ca', 'manuf_ba_conf_de', 'export_orders_fr', 'x_vol_world2', 'manuf_ba_conf_pl', 'fc_gdp_uk', 'x_vol_afr', 'fc_x_us', 'ipi_de', 'ipi_it', 'serv_emp_fut_nl', 'x_servs_us', 'manuf_ba_conf_it', 'fc_gdp_oecd', 'p_manuf', 'container_hk', 'x_ru', 'ipi_jp', 'fc_x_de', 'bci_br', 'manuf_emp_fut_it', 'x_in', 'x_us']variables_dict["x_vol_world2"] = ['x_vol_world2', 'x_servs_ez', 'ipi_jp', 'manuf_shipments_us', 'ipi_fr', 'rti_vol_oecd', 'serv_conf_fr', 'air_freight_hkg', 'fc_gdp_jp', 'bci_jp', 'manuf_emp_fut_it', 'manuf_orders_de', 'bci_kr', 'bci_oecd', 'ipi_uk', 'ipi_it', 'x_vol_world', 'manuf_ba_conf_nl', 'rti_vol_us', 'manuf_emp_fut_de', 'constr_ca', 'export_orders_nl', 'x_vol_afr']variables_dict["x_servs_world"] = ['x_servs_us', 'fc_gdp_us', 'manuf_emp_fut_it', 'x_servs_world', 'p_manuf', 'x_servs_sg', 'manuf_orders_us_2', 'ipi_eu27', 'fc_x_de', 'export_orders_uk', 'export_orders_it', 'cci_br', 'rti_val_es', 'rti_val_fr', 'ipi_jp', 'manuf_orders_it', 'x_world', 'fc_x_us', 'x_vol_ez', 'x_nl', 'bci_nl']if retrain:    ### training, use 2020-03-01 dataset    train = pd.read_csv(data_directory + "output/2020-03-01_database_tf.csv", parse_dates=["date"])    train = train.loc[train.date <= "2019-12-01",:]        # parameters for model_selection    n_timesteps_dict = {}; n_timesteps_dict["x_world"] = 9; n_timesteps_dict["x_vol_world2"] = 7; n_timesteps_dict["x_servs_world"] = 7;     train_episodes_dict = {}; train_episodes_dict["x_world"] = 200; train_episodes_dict["x_vol_world2"] = 200; train_episodes_dict["x_servs_world"] = 200;     batch_size_dict = {}; batch_size_dict["x_world"] = 40; batch_size_dict["x_vol_world2"] = 45; batch_size_dict["x_servs_world"] = 45;     n_hidden_dict = {}; n_hidden_dict["x_world"] = 40; n_hidden_dict["x_vol_world2"] = 50; n_hidden_dict["x_servs_world"] = 50;     n_layers_dict = {}; n_layers_dict["x_world"] = 1; n_layers_dict["x_vol_world2"] = 1; n_layers_dict["x_servs_world"] = 4;     for target in targets:        train_i = train.loc[:, ["date"] + variables_dict[target]]        # train lstm        model = LSTM(            data=train_i,             target_variable=target,             n_timesteps=n_timesteps_dict[target],            fill_na_func=np.nanmean,            fill_ragged_edges_func=np.nanmean,            n_models=10,            train_episodes=train_episodes_dict[target],            batch_size=batch_size_dict[target],            lr=0.01,            decay=0.98,            n_hidden=n_hidden_dict[target],            n_layers=n_layers_dict[target],            dropout=0,            criterion=torch.nn.MSELoss()        )                model.train(quiet=True)                dill.dump(model, open("trained_models/" + target + ".pkl", mode="wb"))                # generating updatefiles = os.listdir(f"{data_directory}/output/")files = [x[:10] for x in files if "_tf" in x]  files.sort()result = pd.DataFrame(columns=["date_forecast", "series", "value", "target", "target_period"])# ignore news history, do all from scratchif False:    news_history = result.copy()for target in targets:    model = dill.load(open("trained_models/" + target + ".pkl", "rb", -1))    for target_period in target_periods:        print(f"{target}: {target_period}")        for i in range(1, len(files)):            # only do if target-vintage not yet in the data            if len(news_history.loc[lambda x: (x.date_forecast == files[i]) & (x.target_period == target_period) & (x.target == target),:]) == 0:                # only do if target date within 93 days of file date                if (np.abs((datetime.datetime.strptime(files[i], "%Y-%m-%d") - datetime.datetime.strptime(target_period, "%Y-%m-%d")).days) <= 93):                    data_i = pd.read_csv(data_directory + "output/" + files[i] + "_database_tf.csv", parse_dates=["date"])                    data_i = data_i.loc[:, ["date"] + variables_dict[target]]                    data_i = add_last_dates(data_i, target_period)                    # for news                    data_i_old = pd.read_csv(data_directory + "output/" + files[i-1] + "_database_tf.csv", parse_dates=["date"])                    data_i_old = data_i_old.loc[:, ["date"] + variables_dict[target]]                    # force all dataframes to have same number of rows                    data_i_old = data_i.loc[:, ["date"]].merge(data_i_old, on="date", how="left")                                        # make sure target date is in                    data_i = add_last_dates(data_i, target_period)                    data_i_old = add_last_dates(data_i_old, target_period)                                        # news                    news = model.gen_news(target_period, data_i_old, data_i)                    tmp = news["news"].copy().drop("news", axis=1)                    tmp.columns = ["series", "value"]                    tmp.loc[tmp.series == "revisions", "series"] = "impact_revisions"                    tmp.loc[len(tmp), "series"] = "forecast"                    tmp.loc[len(tmp)-1, "value"] = news["new_pred"]                    tmp["date_forecast"] = files[i]                    tmp["target"] = target                    tmp["target_period"] = target_period                                        result = result.append(tmp, ignore_index=True).reset_index(drop=True)news_history = news_history.append(result, ignore_index=True).reset_index(drop=True)news_history.to_csv(f"{unctad_web_directory}/nowcasts/data/lstm.csv", index=False)print('\033[92m' + "LSTM successfully updated")