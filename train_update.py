import datetimefrom dateutil.relativedelta import relativedeltaimport pandas as pdimport numpy as npimport torchimport dillimport osfrom nowcast_lstm.LSTM import LSTM### data informationdata_directory = "/Users/danhopp/dhopp1/UNCTAD/nowcast_data_update/"unctad_web_directory = "/Users/danhopp/dhopp1/UNCTAD/unctad-nowcast-web/"retrain = Falsetargets = ["x_world", "x_vol_world2", "x_servs_world"]target_periods = ["2020-06-01", "2020-09-01", "2020-12-01", "2021-03-01", "2021-06-01", "2021-09-01", "2021-12-01"]if retrain:    ### training, use 2020-03-01 dataset    train = pd.read_csv(data_directory + "output/2020-03-01_database_tf.csv", parse_dates=["date"])    train = train.loc[train.date <= "2019-12-01",:]        # final model parameters and variables from selection    variables_dict = {}    variables_dict["x_world"] = ['x_world', 'bci_nl', 'constr_ca', 'manuf_ba_conf_de', 'export_orders_fr', 'x_vol_world2', 'manuf_ba_conf_pl', 'fc_gdp_uk', 'x_vol_afr', 'fc_x_us', 'ipi_de', 'ipi_it', 'serv_emp_fut_nl', 'x_servs_us', 'manuf_ba_conf_it', 'fc_gdp_oecd', 'p_manuf', 'container_hk', 'x_ru', 'ipi_jp', 'fc_x_de', 'bci_br', 'manuf_emp_fut_it', 'x_in', 'x_us']    variables_dict["x_vol_world2"] = ['x_vol_world2', 'x_servs_ez', 'ipi_jp', 'manuf_shipments_us', 'ipi_fr', 'rti_vol_oecd', 'serv_conf_fr', 'air_freight_hkg', 'fc_gdp_jp', 'bci_jp', 'manuf_emp_fut_it', 'manuf_orders_de', 'bci_kr', 'bci_oecd', 'ipi_uk', 'ipi_it', 'x_vol_world', 'manuf_ba_conf_nl', 'rti_vol_us', 'manuf_emp_fut_de', 'constr_ca', 'export_orders_nl', 'x_vol_afr']    variables_dict["x_servs_world"] = ['x_servs_us', 'fc_gdp_us', 'manuf_emp_fut_it', 'x_servs_world', 'p_manuf', 'x_servs_sg', 'manuf_orders_us_2', 'ipi_eu27', 'fc_x_de', 'export_orders_uk', 'export_orders_it', 'cci_br', 'rti_val_es', 'rti_val_fr', 'ipi_jp', 'manuf_orders_it', 'x_world', 'fc_x_us', 'x_vol_ez', 'x_nl', 'bci_nl']        # parameters for model_selection    n_timesteps_dict = {}; n_timesteps_dict["x_world"] = 9; n_timesteps_dict["x_vol_world2"] = 7; n_timesteps_dict["x_servs_world"] = 7;     train_episodes_dict = {}; train_episodes_dict["x_world"] = 200; train_episodes_dict["x_vol_world2"] = 200; train_episodes_dict["x_servs_world"] = 200;     batch_size_dict = {}; batch_size_dict["x_world"] = 40; batch_size_dict["x_vol_world2"] = 45; batch_size_dict["x_servs_world"] = 45;     n_hidden_dict = {}; n_hidden_dict["x_world"] = 40; n_hidden_dict["x_vol_world2"] = 50; n_hidden_dict["x_servs_world"] = 50;     n_layers_dict = {}; n_layers_dict["x_world"] = 1; n_layers_dict["x_vol_world2"] = 1; n_layers_dict["x_servs_world"] = 4;     for target in targets:        train_i = train.loc[:, ["date"] + variables_dict[target]]        # train lstm        model = LSTM(            data=train_i,             target_variable=target,             n_timesteps=n_timesteps_dict[target],            fill_na_func=np.nanmean,            fill_ragged_edges_func=np.nanmean,            n_models=10,            train_episodes=train_episodes_dict[target],            batch_size=batch_size_dict[target],            lr=0.01,            decay=0.98,            n_hidden=n_hidden_dict[target],            n_layers=n_layers_dict[target],            dropout=0,            criterion=torch.nn.MSELoss()        )                model.train(quiet=True)                dill.dump(model, open("trained_models/" + target + ".pkl", mode="wb"))                # generating updatefiles = os.listdir(f"{data_directory}/output/")files = [x[:10] for x in files if "_tf" in x]  files.sort()result = pd.DataFrame(columns=["target_period", "pred_date", "target", "prediction"])for target in targets:    model = dill.load(open("trained_models/" + target + ".pkl", "rb", -1))    for target_period in target_periods:        print(f"{target}: {target_period}")        for file in files:            # only do if target date within 93 days of file date            if (np.abs((datetime.datetime.strptime(file, "%Y-%m-%d") - datetime.datetime.strptime(target_period, "%Y-%m-%d")).days) <= 93):                data_i = pd.read_csv(data_directory + "output/" + file + "_database_tf.csv", parse_dates=["date"])                data_i = data_i.loc[:, ["date"] + variables_dict[target]]                                # make sure target date is in                last_date = datetime.datetime.strptime(datetime.datetime.strftime(np.max(data_i.date), "%Y-%m-%d"), "%Y-%m-%d")                 period_date = datetime.datetime.strptime(target_period, "%Y-%m-%d")                months_add = (period_date.year - last_date.year) * 12 + (period_date.month - last_date.month)                if months_add > 0:                    for i in range(months_add):                        data_i.loc[len(data_i), "date"] = data_i.loc[len(data_i)-1, "date"] + relativedelta(months=1)                                           pred = model.predict(data_i)                pred = pred.loc[pred.date == target_period, "predictions"].values[0]                                tmp = pd.DataFrame({                    "target_period": target_period,                    "pred_date": file,                    "target": target,                    "prediction": pred                }, index=[0])                result = result.append(tmp, ignore_index=True).reset_index(drop=True)result.to_csv(f"{unctad_web_directory}/nowcasts/data/lstm.csv", index=False)print('\033[92m' + "LSTM successfully updated")